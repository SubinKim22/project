{
 "cells": [
  {
   "cell_type": "raw",
   "id": "00675ff2",
   "metadata": {},
   "source": [
    "```\n",
    "22.04.04\n",
    "1. NN / 256-128-64-20 / adam / batch=64  =>  0.6265\n",
    "2. NN / 256-128(Drop 0.5)-64(Drop 0.5)-20 / elu / adam / batch=128  =>  0.6811 \n",
    "3. NN / 256-128(Drop 0.5)-64(Drop 0.5)-20 / elu / Nadam / batch=256  =>  0.6613\n",
    "\n",
    "22.04.05\n",
    "1. NN / 256-128(Drop 0.5)-64(Drop 0.5)-20 / elu / adam / batch=256  =>  0.6798\n",
    "2. KFold / NN / 256-128(Drop 0.5)-64(Drop 0.5)-20 / elu / adam / batch=128  =>  0.7337 (best)\n",
    "3. KFold / NN / 256-128(Drop 0.5)-64(Drop 0.5)-20 / tanh / adam / batch=128  =>  0.7328\n",
    "\n",
    "```\n",
    "count vs tfidf\n",
    "불용어 삭제 + 토큰화\n",
    "LSTM 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1a9a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "임베딩 알고리즘 변경\n",
    "분류 알고리즘 변경 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbed0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "793b46e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 17558348593734113906\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ab7e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "bc4f730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train.drop('id', axis=1, inplace=True)\n",
    "test.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "75f4130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def clean_text(texts): \n",
    "  corpus = [] \n",
    "  for i in range(0, len(texts)): \n",
    "\n",
    "    review = re.sub(r'[@%\\\\*=()/~#&\\+á?\\xc3\\xa1\\-\\|\\.\\:\\;\\!\\-\\,\\_\\~\\$\\'\\\"\\n\\]\\[\\>]', '',texts[i]) #@%*=()/+ 와 같은 문장부호 제거\n",
    "    review = re.sub(r'\\d+','', review)#숫자 제거\n",
    "    review = review.lower() #소문자 변환\n",
    "    review = re.sub(r'\\s+', ' ', review) #extra space 제거\n",
    "    review = re.sub(r'<[^>]+>','',review) #Html tags 제거\n",
    "    review = re.sub(r'\\s+', ' ', review) #spaces 제거\n",
    "    review = re.sub(r\"^\\s+\", '', review) #space from start 제거\n",
    "    review = re.sub(r'\\s+$', '', review) #space from the end 제거\n",
    "    review = re.sub(r'_', ' ', review) #space from the end 제거\n",
    "    corpus.append(review) \n",
    "  \n",
    "  return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "6d0bc1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>they were and even if washington might conside...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we run spacenews views on our stareach bbs a l...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not to worry the masons have been demonized an...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>only brendan mckay or maybe arf would come to ...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>help i am running some sample problems from or...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  they were and even if washington might conside...      10\n",
       "1  we run spacenews views on our stareach bbs a l...      14\n",
       "2  not to worry the masons have been demonized an...      19\n",
       "3  only brendan mckay or maybe arf would come to ...      17\n",
       "4  help i am running some sample problems from or...       5"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = clean_text(train['text']) #메소드 적용\n",
    "train['text'] = temp\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2d989321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the vlide adapter can be much faster then the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yeah in a fire that reportedly burned hotter t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>judge i grant you immunity from whatever may b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i too put a corbin seat on my hawk i got the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do i ever after years of having health problem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  the vlide adapter can be much faster then the ...\n",
       "1  yeah in a fire that reportedly burned hotter t...\n",
       "2  judge i grant you immunity from whatever may b...\n",
       "3  i too put a corbin seat on my hawk i got the s...\n",
       "4  do i ever after years of having health problem..."
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = clean_text(test['text']) #메소드 적용\n",
    "test['text'] = temp\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "daa0c7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train['text']\n",
    "train_y = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "76b418ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       they were and even if washington might conside...\n",
       "1       we run spacenews views on our stareach bbs a l...\n",
       "2       not to worry the masons have been demonized an...\n",
       "3       only brendan mckay or maybe arf would come to ...\n",
       "4       help i am running some sample problems from or...\n",
       "                              ...                        \n",
       "9228    precisely why not cuba why not the hatians are...\n",
       "9229    your custom resume on disk macintosh or ibm co...\n",
       "9230    throughout the years of the israelarabpalestin...\n",
       "9231    does anyone know if there are any devices avai...\n",
       "9232    give me a break chum are you telling me that c...\n",
       "Name: text, Length: 9233, dtype: object"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49519491",
   "metadata": {},
   "source": [
    "# baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131931cc",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "72618490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "edff6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b159a795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "c2033064",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = vectorizer.transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "494c0a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9233x143548 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 861642 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "97532c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['and', 'been', 'bust', 'complete', 'consider', 'druce', 'even',\n",
       "        'goals', 'has', 'hereonly', 'id', 'if', 'in', 'might', 'minute',\n",
       "        'patty', 'reworkthat', 'they', 'trade', 'utter', 'washington',\n",
       "        'were'], dtype='<U650')]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.inverse_transform(train_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "bb4d46fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test.text #문서 데이터 생성\n",
    "\n",
    "test_X_vect = vectorizer.transform(test_X) #문서 데이터 transform \n",
    "#test 데이터를 대상으로 fit_transform 메소드를 실행하는 것은 test 데이터를 활용해 vectorizer 를 학습 시키는 것으롤 data leakage 에 해당합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5b70357b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9233x143548 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 740685 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e76fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4d55a29",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67dc14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96be100",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5583664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3545e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = vectorizer.transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4c4d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd2330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.inverse_transform(train_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de42959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4ffb11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e908bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "581b74e4",
   "metadata": {},
   "source": [
    "# 알고리즘 실험실"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86e46abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "641b63b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse = False)\n",
    "y = ohe.fit_transform(train[['target']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712c9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=train_X.shape[1], activation = 'elu'))\n",
    "model.add(Dense(128, activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(20, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8837a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_X, y, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd50c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_X_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fda00f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2194e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b7f351",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "submission['target'] = np.argmax(pred, axis = 1)\n",
    "\n",
    "submission\n",
    "\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48a9a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73426b98",
   "metadata": {},
   "source": [
    "# Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "eda1d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "61cf8ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eadbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 10, random_state = 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca4d9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn_acc = []\n",
    "nn_pred = np.zeros((y.shape[0], y.shape[1]))\n",
    "\n",
    "for i, (tr_idx, val_idx) in enumerate(skf.split(train_X, train_y)) :\n",
    "    print(f'{i + 1} Fold Training.....')\n",
    "    tr_x, tr_y = train_X[tr_idx], y[tr_idx]\n",
    "    val_x, val_y = train_X[val_idx], y[val_idx]\n",
    "    \n",
    "    ### NN 모델\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=train_X.shape[1], activation = 'elu'))\n",
    "    model.add(Dense(128, activation='elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(20, activation='softmax'))\n",
    "\n",
    "    mc = ModelCheckpoint(f'model_{i + 1}.h5', save_best_only = True, monitor = 'val_accuracy', mode = 'max', verbose = 0)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "    result = model.fit(tr_x, tr_y, validation_data = (val_x, val_y), epochs = 10, batch_size = 128, callbacks = [mc], verbose = 1)\n",
    "\n",
    "    ### 최고 성능 기록 모델 Load\n",
    "    best = load_model(f'model_{i + 1}.h5')\n",
    "    ### validation predict\n",
    "    val_pred = best.predict(val_x)\n",
    "    ### 확률값 중 최대값을 클래스로 매칭\n",
    "    val_cls = np.argmax(val_pred, axis = 1)\n",
    "    ### Fold별 val_mae 산출\n",
    "    fold_nn_acc = accuracy_score(np.argmax(val_y, axis = 1), val_cls)\n",
    "    nn_acc.append(fold_nn_acc)\n",
    "    print(f'{i + 1} Fold nn acc = {fold_nn_acc}\\n')\n",
    "\n",
    "    ### Fold별 test 데이터에 대한 예측값 생성 및 앙상블\n",
    "    fold_pred = best.predict(test_X_vect) / skf.n_splits\n",
    "    nn_pred += fold_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362e9ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(nn_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f24638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "submission['target'] = np.argmax(nn_pred, axis = 1)\n",
    "\n",
    "submission\n",
    "\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d45ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c5387d1",
   "metadata": {},
   "source": [
    "## 불용어처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "79d334fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train.drop('id', axis=1, inplace=True)\n",
    "test.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "e238d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def clean_text(texts): \n",
    "  corpus = [] \n",
    "  for i in range(0, len(texts)): \n",
    "\n",
    "    review = re.sub(r'[@%\\\\*=()/~#&\\+á?\\xc3\\xa1\\-\\|\\.\\:\\;\\!\\-\\,\\_\\~\\$\\'\\\"\\n\\]\\[\\>]', '',texts[i]) #@%*=()/+ 와 같은 문장부호 제거\n",
    "    review = re.sub(r'\\d+','', review)#숫자 제거\n",
    "    review = review.lower() #소문자 변환\n",
    "    review = re.sub(r'\\s+', ' ', review) #extra space 제거\n",
    "    review = re.sub(r'<[^>]+>','',review) #Html tags 제거\n",
    "    review = re.sub(r'\\s+', ' ', review) #spaces 제거\n",
    "    review = re.sub(r\"^\\s+\", '', review) #space from start 제거\n",
    "    review = re.sub(r'\\s+$', '', review) #space from the end 제거\n",
    "    review = re.sub(r'_', ' ', review) #space from the end 제거\n",
    "    corpus.append(review) \n",
    "  \n",
    "  return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "dfba4f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>they were and even if washington might conside...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we run spacenews views on our stareach bbs a l...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not to worry the masons have been demonized an...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>only brendan mckay or maybe arf would come to ...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>help i am running some sample problems from or...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  they were and even if washington might conside...      10\n",
       "1  we run spacenews views on our stareach bbs a l...      14\n",
       "2  not to worry the masons have been demonized an...      19\n",
       "3  only brendan mckay or maybe arf would come to ...      17\n",
       "4  help i am running some sample problems from or...       5"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = clean_text(train['text']) #메소드 적용\n",
    "train['text'] = temp\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "6d730528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the vlide adapter can be much faster then the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yeah in a fire that reportedly burned hotter t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>judge i grant you immunity from whatever may b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i too put a corbin seat on my hawk i got the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do i ever after years of having health problem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  the vlide adapter can be much faster then the ...\n",
       "1  yeah in a fire that reportedly burned hotter t...\n",
       "2  judge i grant you immunity from whatever may b...\n",
       "3  i too put a corbin seat on my hawk i got the s...\n",
       "4  do i ever after years of having health problem..."
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = clean_text(test['text']) #메소드 적용\n",
    "test['text'] = temp\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "7ee63a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train['text']\n",
    "train_y = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "196d11e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       they were and even if washington might conside...\n",
       "1       we run spacenews views on our stareach bbs a l...\n",
       "2       not to worry the masons have been demonized an...\n",
       "3       only brendan mckay or maybe arf would come to ...\n",
       "4       help i am running some sample problems from or...\n",
       "                              ...                        \n",
       "9228    precisely why not cuba why not the hatians are...\n",
       "9229    your custom resume on disk macintosh or ibm co...\n",
       "9230    throughout the years of the israelarabpalestin...\n",
       "9231    does anyone know if there are any devices avai...\n",
       "9232    give me a break chum are you telling me that c...\n",
       "Name: text, Length: 9233, dtype: object"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "ea17eafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "ba58a468",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        even washington might consider patty bust id ...\n",
       "1        run spacenews views stareach bbs localoperati...\n",
       "2        worry masons demonized harrassed almost every...\n",
       "3        brendan mckay maybe arf would come rescue naz...\n",
       "4        help running sample problems oreilly volume x...\n",
       "                              ...                        \n",
       "9228     precisely cuba hatians ruled thugs elected le...\n",
       "9229     custom resume disk macintosh ibm compatible n...\n",
       "9230     throughout years israelarabpalestinian confli...\n",
       "9231     anyone know devices available mac whichwill i...\n",
       "9232     give break chum telling clinton reno know bat...\n",
       "Name: text, Length: 9233, dtype: object"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(train_X)):\n",
    "    a = train_X[i].split(' ')\n",
    "    result = ''\n",
    "    for word in a: \n",
    "        if word not in stop_words: \n",
    "            result = result + ' ' + word \n",
    "    train_X[i] = result\n",
    "\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f34ee59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vlide adapter much faster normal ide depends ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yeah fire reportedly burned hotter degrees ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>judge grant immunity whatever may learned key...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>put corbin seat hawk got solo seat whichcould...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ever years health problems beencleared waller...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9228</th>\n",
       "      <td>texas cannot carry handgun period either conc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9229</th>\n",
       "      <td>yes want concentrate development issues ive c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9230</th>\n",
       "      <td>know megadrives worked perfectly mymac plus p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9231</th>\n",
       "      <td>oops quite right got busy saved franks last p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9232</th>\n",
       "      <td>actually like stuff phase molphase b endedwit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9233 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0      vlide adapter much faster normal ide depends ...\n",
       "1      yeah fire reportedly burned hotter degrees ho...\n",
       "2      judge grant immunity whatever may learned key...\n",
       "3      put corbin seat hawk got solo seat whichcould...\n",
       "4      ever years health problems beencleared waller...\n",
       "...                                                 ...\n",
       "9228   texas cannot carry handgun period either conc...\n",
       "9229   yes want concentrate development issues ive c...\n",
       "9230   know megadrives worked perfectly mymac plus p...\n",
       "9231   oops quite right got busy saved franks last p...\n",
       "9232   actually like stuff phase molphase b endedwit...\n",
       "\n",
       "[9233 rows x 1 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(test.text)):\n",
    "    a = test.text[i].split(' ')\n",
    "    result = ''\n",
    "    for word in a: \n",
    "        if word not in stop_words: \n",
    "            result = result + ' ' + word \n",
    "    test.text[i] = result\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8205919c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "b8d3180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "ead7eb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a8b019cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d4d99555",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = vectorizer.transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "f58e493b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9233x143522 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 649556 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "77ca2172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['bust', 'complete', 'consider', 'druce', 'even', 'goals',\n",
       "        'hereonly', 'id', 'might', 'minute', 'patty', 'reworkthat',\n",
       "        'trade', 'utter', 'washington'], dtype='<U650')]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.inverse_transform(train_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "88d13fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test.text #문서 데이터 생성\n",
    "\n",
    "test_X_vect = vectorizer.transform(test_X) #문서 데이터 transform \n",
    "#test 데이터를 대상으로 fit_transform 메소드를 실행하는 것은 test 데이터를 활용해 vectorizer 를 학습 시키는 것으롤 data leakage 에 해당합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "15e473e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9233x143522 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 530833 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e51093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "fece2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 10, random_state = 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "4ec4453b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Fold Training.....\n",
      "Epoch 1/10\n",
      "65/65 [==============================] - 15s 228ms/step - loss: 2.2047 - accuracy: 0.4203 - val_loss: 1.4451 - val_accuracy: 0.6883\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 12s 184ms/step - loss: 0.9334 - accuracy: 0.8009 - val_loss: 1.1006 - val_accuracy: 0.7154\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 11s 172ms/step - loss: 0.4746 - accuracy: 0.9225 - val_loss: 1.0705 - val_accuracy: 0.7154\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.2744 - accuracy: 0.9566 - val_loss: 1.0754 - val_accuracy: 0.7110\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.2121 - accuracy: 0.9682 - val_loss: 1.1320 - val_accuracy: 0.7024\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 12s 187ms/step - loss: 0.1775 - accuracy: 0.9718 - val_loss: 1.1450 - val_accuracy: 0.7078\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 12s 183ms/step - loss: 0.1595 - accuracy: 0.9746 - val_loss: 1.1976 - val_accuracy: 0.7035\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.1380 - accuracy: 0.9767 - val_loss: 1.2283 - val_accuracy: 0.6970\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 11s 175ms/step - loss: 0.1654 - accuracy: 0.9769 - val_loss: 1.2313 - val_accuracy: 0.6926\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.1132 - accuracy: 0.9779 - val_loss: 1.2677 - val_accuracy: 0.7035\n",
      "1 Fold nn acc = 0.7153679653679653\n",
      "\n",
      "2 Fold Training.....\n",
      "Epoch 1/10\n",
      "65/65 [==============================] - 12s 188ms/step - loss: 2.2362 - accuracy: 0.4257 - val_loss: 1.4442 - val_accuracy: 0.6807\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 15s 227ms/step - loss: 0.9513 - accuracy: 0.7912 - val_loss: 1.1051 - val_accuracy: 0.6970\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 11s 174ms/step - loss: 0.4753 - accuracy: 0.9237 - val_loss: 1.0530 - val_accuracy: 0.6937\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 11s 171ms/step - loss: 0.2640 - accuracy: 0.9594 - val_loss: 1.0862 - val_accuracy: 0.6905\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 11s 173ms/step - loss: 0.2259 - accuracy: 0.9692 - val_loss: 1.1107 - val_accuracy: 0.6851\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 11s 175ms/step - loss: 0.2178 - accuracy: 0.9763 - val_loss: 1.1543 - val_accuracy: 0.6872\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 11s 174ms/step - loss: 0.1556 - accuracy: 0.9763 - val_loss: 1.1751 - val_accuracy: 0.6905\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 12s 185ms/step - loss: 0.1236 - accuracy: 0.9791 - val_loss: 1.2062 - val_accuracy: 0.6818\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 11s 176ms/step - loss: 0.1166 - accuracy: 0.9797 - val_loss: 1.2346 - val_accuracy: 0.6851\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 11s 177ms/step - loss: 0.0954 - accuracy: 0.9817 - val_loss: 1.2916 - val_accuracy: 0.6721\n",
      "2 Fold nn acc = 0.696969696969697\n",
      "\n",
      "3 Fold Training.....\n",
      "Epoch 1/10\n",
      "65/65 [==============================] - 16s 242ms/step - loss: 2.2162 - accuracy: 0.4276 - val_loss: 1.3661 - val_accuracy: 0.6742\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 12s 186ms/step - loss: 0.9133 - accuracy: 0.8045 - val_loss: 1.0896 - val_accuracy: 0.7056\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 12s 182ms/step - loss: 0.4138 - accuracy: 0.9277 - val_loss: 1.0676 - val_accuracy: 0.6905\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 12s 177ms/step - loss: 0.2642 - accuracy: 0.9597 - val_loss: 1.1211 - val_accuracy: 0.6818\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.2159 - accuracy: 0.9686 - val_loss: 1.1762 - val_accuracy: 0.6948\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 12s 184ms/step - loss: 0.2147 - accuracy: 0.9704 - val_loss: 1.2052 - val_accuracy: 0.6894\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 11s 175ms/step - loss: 0.1594 - accuracy: 0.9736 - val_loss: 1.3445 - val_accuracy: 0.6721\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 11s 174ms/step - loss: 0.1634 - accuracy: 0.9756 - val_loss: 1.3294 - val_accuracy: 0.6786\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 11s 175ms/step - loss: 0.1584 - accuracy: 0.9752 - val_loss: 1.3634 - val_accuracy: 0.6775\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 12s 181ms/step - loss: 0.1629 - accuracy: 0.9769 - val_loss: 1.3887 - val_accuracy: 0.6732\n",
      "3 Fold nn acc = 0.7056277056277056\n",
      "\n",
      "4 Fold Training.....\n",
      "Epoch 1/10\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 2.2624 - accuracy: 0.4149 - val_loss: 1.4877 - val_accuracy: 0.6674\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 14s 222ms/step - loss: 0.9360 - accuracy: 0.7986 - val_loss: 1.1538 - val_accuracy: 0.7010\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 12s 176ms/step - loss: 0.4554 - accuracy: 0.9197 - val_loss: 1.1597 - val_accuracy: 0.6966\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 11s 176ms/step - loss: 0.2881 - accuracy: 0.9587 - val_loss: 1.2463 - val_accuracy: 0.6826\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 12s 177ms/step - loss: 0.1871 - accuracy: 0.9711 - val_loss: 1.2484 - val_accuracy: 0.6858\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.1439 - accuracy: 0.9762 - val_loss: 1.3424 - val_accuracy: 0.6804\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 12s 182ms/step - loss: 0.1368 - accuracy: 0.9780 - val_loss: 1.3728 - val_accuracy: 0.6847\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 12s 183ms/step - loss: 0.1249 - accuracy: 0.9800 - val_loss: 1.4071 - val_accuracy: 0.6782\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.1328 - accuracy: 0.9795 - val_loss: 1.4842 - val_accuracy: 0.6891\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 12s 185ms/step - loss: 0.1353 - accuracy: 0.9794 - val_loss: 1.4741 - val_accuracy: 0.6880\n",
      "4 Fold nn acc = 0.7009750812567714\n",
      "\n",
      "5 Fold Training.....\n",
      "Epoch 1/10\n",
      "65/65 [==============================] - 13s 189ms/step - loss: 2.2304 - accuracy: 0.4017 - val_loss: 1.4642 - val_accuracy: 0.6685\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 19s 301ms/step - loss: 0.9348 - accuracy: 0.7895 - val_loss: 1.1350 - val_accuracy: 0.7140\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 11s 172ms/step - loss: 0.4318 - accuracy: 0.9226 - val_loss: 1.1397 - val_accuracy: 0.7021\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 11s 172ms/step - loss: 0.2684 - accuracy: 0.9556 - val_loss: 1.1833 - val_accuracy: 0.7140\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 11s 177ms/step - loss: 0.2264 - accuracy: 0.9681 - val_loss: 1.1851 - val_accuracy: 0.7042\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 12s 183ms/step - loss: 0.1707 - accuracy: 0.9720 - val_loss: 1.2294 - val_accuracy: 0.7086\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.1448 - accuracy: 0.9761 - val_loss: 1.2493 - val_accuracy: 0.6945\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.1512 - accuracy: 0.9775 - val_loss: 1.2901 - val_accuracy: 0.6966\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 11s 177ms/step - loss: 0.1174 - accuracy: 0.9801 - val_loss: 1.3205 - val_accuracy: 0.7042\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 11s 171ms/step - loss: 0.1259 - accuracy: 0.9786 - val_loss: 1.3494 - val_accuracy: 0.6956\n",
      "5 Fold nn acc = 0.71397616468039\n",
      "\n",
      "6 Fold Training.....\n",
      "Epoch 1/10\n",
      "65/65 [==============================] - 13s 194ms/step - loss: 2.2341 - accuracy: 0.4084 - val_loss: 1.5074 - val_accuracy: 0.6555\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 13s 196ms/step - loss: 0.9374 - accuracy: 0.7993 - val_loss: 1.2038 - val_accuracy: 0.6728\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 0.4395 - accuracy: 0.9226 - val_loss: 1.1728 - val_accuracy: 0.6858\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 12s 189ms/step - loss: 0.2579 - accuracy: 0.9621 - val_loss: 1.1909 - val_accuracy: 0.6923\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 12s 184ms/step - loss: 0.2363 - accuracy: 0.9693 - val_loss: 1.2277 - val_accuracy: 0.6858\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 12s 184ms/step - loss: 0.1884 - accuracy: 0.9750 - val_loss: 1.2441 - val_accuracy: 0.6815\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 11s 171ms/step - loss: 0.1967 - accuracy: 0.9730 - val_loss: 1.3198 - val_accuracy: 0.6826\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 11s 171ms/step - loss: 0.1787 - accuracy: 0.9765 - val_loss: 1.3469 - val_accuracy: 0.6869\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 11s 171ms/step - loss: 0.1236 - accuracy: 0.9776 - val_loss: 1.4236 - val_accuracy: 0.6652\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 11s 171ms/step - loss: 0.1585 - accuracy: 0.9803 - val_loss: 1.3941 - val_accuracy: 0.6771\n",
      "6 Fold nn acc = 0.6923076923076923\n",
      "\n",
      "7 Fold Training.....\n",
      "Epoch 1/10\n",
      "65/65 [==============================] - 15s 227ms/step - loss: 2.2706 - accuracy: 0.4119 - val_loss: 1.5379 - val_accuracy: 0.6739\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 18s 273ms/step - loss: 0.9886 - accuracy: 0.7963 - val_loss: 1.2281 - val_accuracy: 0.7064\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 15s 227ms/step - loss: 0.5062 - accuracy: 0.9150 - val_loss: 1.2018 - val_accuracy: 0.7086\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 12s 190ms/step - loss: 0.3089 - accuracy: 0.9580 - val_loss: 1.2278 - val_accuracy: 0.7151\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 11s 175ms/step - loss: 0.2339 - accuracy: 0.9658 - val_loss: 1.2745 - val_accuracy: 0.7031\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 11s 175ms/step - loss: 0.1993 - accuracy: 0.9710 - val_loss: 1.3030 - val_accuracy: 0.6923\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.1822 - accuracy: 0.9747 - val_loss: 1.3034 - val_accuracy: 0.6977\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 11s 176ms/step - loss: 0.1423 - accuracy: 0.9776 - val_loss: 1.3696 - val_accuracy: 0.6956\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 11s 176ms/step - loss: 0.1382 - accuracy: 0.9767 - val_loss: 1.4116 - val_accuracy: 0.6880\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 11s 175ms/step - loss: 0.1475 - accuracy: 0.9787 - val_loss: 1.4059 - val_accuracy: 0.6999\n",
      "7 Fold nn acc = 0.7150595882990249\n",
      "\n",
      "8 Fold Training.....\n",
      "Epoch 1/10\n",
      "65/65 [==============================] - 13s 188ms/step - loss: 2.2350 - accuracy: 0.4136 - val_loss: 1.3935 - val_accuracy: 0.6782\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 12s 192ms/step - loss: 0.9305 - accuracy: 0.8072 - val_loss: 1.1117 - val_accuracy: 0.6999\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 15s 231ms/step - loss: 0.4214 - accuracy: 0.9261 - val_loss: 1.0754 - val_accuracy: 0.7042\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 12s 189ms/step - loss: 0.2496 - accuracy: 0.9609 - val_loss: 1.0949 - val_accuracy: 0.7086\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 12s 177ms/step - loss: 0.2126 - accuracy: 0.9710 - val_loss: 1.1529 - val_accuracy: 0.6934\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 12s 181ms/step - loss: 0.1720 - accuracy: 0.9726 - val_loss: 1.2415 - val_accuracy: 0.6771\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 12s 185ms/step - loss: 0.1653 - accuracy: 0.9746 - val_loss: 1.2580 - val_accuracy: 0.6923\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.1349 - accuracy: 0.9774 - val_loss: 1.2455 - val_accuracy: 0.6847\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 11s 174ms/step - loss: 0.1328 - accuracy: 0.9769 - val_loss: 1.2976 - val_accuracy: 0.6858\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 11s 170ms/step - loss: 0.1322 - accuracy: 0.9794 - val_loss: 1.3009 - val_accuracy: 0.6761\n",
      "8 Fold nn acc = 0.7085590465872156\n",
      "\n",
      "9 Fold Training.....\n",
      "Epoch 1/10\n",
      "65/65 [==============================] - 13s 193ms/step - loss: 2.1930 - accuracy: 0.4252 - val_loss: 1.4729 - val_accuracy: 0.6685\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 13s 200ms/step - loss: 0.9378 - accuracy: 0.8000 - val_loss: 1.2372 - val_accuracy: 0.6761\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 13s 192ms/step - loss: 0.4529 - accuracy: 0.9236 - val_loss: 1.1382 - val_accuracy: 0.6836\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.2382 - accuracy: 0.9623 - val_loss: 1.1534 - val_accuracy: 0.6663\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 12s 182ms/step - loss: 0.1907 - accuracy: 0.9687 - val_loss: 1.2700 - val_accuracy: 0.6717\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 12s 181ms/step - loss: 0.1683 - accuracy: 0.9759 - val_loss: 1.3232 - val_accuracy: 0.6696\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.1425 - accuracy: 0.9770 - val_loss: 1.3616 - val_accuracy: 0.6750\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 12s 186ms/step - loss: 0.1288 - accuracy: 0.9788 - val_loss: 1.3645 - val_accuracy: 0.6674\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.1092 - accuracy: 0.9806 - val_loss: 1.4611 - val_accuracy: 0.6652\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 11s 177ms/step - loss: 0.1170 - accuracy: 0.9798 - val_loss: 1.4656 - val_accuracy: 0.6717\n",
      "9 Fold nn acc = 0.6836403033586133\n",
      "\n",
      "10 Fold Training.....\n",
      "Epoch 1/10\n",
      "65/65 [==============================] - 16s 238ms/step - loss: 2.2622 - accuracy: 0.4112 - val_loss: 1.4577 - val_accuracy: 0.6728\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 15s 226ms/step - loss: 0.9754 - accuracy: 0.7850 - val_loss: 1.1158 - val_accuracy: 0.7313\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 11s 175ms/step - loss: 0.4340 - accuracy: 0.9191 - val_loss: 1.0998 - val_accuracy: 0.7259\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 11s 175ms/step - loss: 0.2963 - accuracy: 0.9529 - val_loss: 1.1211 - val_accuracy: 0.7205\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.2145 - accuracy: 0.9663 - val_loss: 1.1541 - val_accuracy: 0.7086\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 12s 187ms/step - loss: 0.1599 - accuracy: 0.9739 - val_loss: 1.1851 - val_accuracy: 0.7259\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.1565 - accuracy: 0.9757 - val_loss: 1.2084 - val_accuracy: 0.7237\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 11s 172ms/step - loss: 0.1421 - accuracy: 0.9786 - val_loss: 1.2855 - val_accuracy: 0.7140\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.1217 - accuracy: 0.9768 - val_loss: 1.2820 - val_accuracy: 0.7031\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 11s 177ms/step - loss: 0.1448 - accuracy: 0.9776 - val_loss: 1.3315 - val_accuracy: 0.7140\n",
      "10 Fold nn acc = 0.7313109425785482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_acc = []\n",
    "nn_pred = np.zeros((y.shape[0], y.shape[1]))\n",
    "\n",
    "for i, (tr_idx, val_idx) in enumerate(skf.split(train_X, train_y)) :\n",
    "    print(f'{i + 1} Fold Training.....')\n",
    "    tr_x, tr_y = train_X[tr_idx], y[tr_idx]\n",
    "    val_x, val_y = train_X[val_idx], y[val_idx]\n",
    "    \n",
    "    ### NN 모델\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=train_X.shape[1], activation = 'elu'))\n",
    "    model.add(Dense(128, activation='elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(20, activation='softmax'))\n",
    "\n",
    "    mc = ModelCheckpoint(f'model_{i + 1}.h5', save_best_only = True, monitor = 'val_accuracy', mode = 'max', verbose = 0)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "    result = model.fit(tr_x, tr_y, validation_data = (val_x, val_y), epochs = 10, batch_size = 128, callbacks = [mc], verbose = 1)\n",
    "\n",
    "    ### 최고 성능 기록 모델 Load\n",
    "    best = load_model(f'model_{i + 1}.h5')\n",
    "    ### validation predict\n",
    "    val_pred = best.predict(val_x)\n",
    "    ### 확률값 중 최대값을 클래스로 매칭\n",
    "    val_cls = np.argmax(val_pred, axis = 1)\n",
    "    ### Fold별 val_mae 산출\n",
    "    fold_nn_acc = accuracy_score(np.argmax(val_y, axis = 1), val_cls)\n",
    "    nn_acc.append(fold_nn_acc)\n",
    "    print(f'{i + 1} Fold nn acc = {fold_nn_acc}\\n')\n",
    "\n",
    "    ### Fold별 test 데이터에 대한 예측값 생성 및 앙상블\n",
    "    fold_pred = best.predict(test_X_vect) / skf.n_splits\n",
    "    nn_pred += fold_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "3fa756d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7063794187033625"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(nn_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "3ca199c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "submission['target'] = np.argmax(nn_pred, axis = 1)\n",
    "\n",
    "submission\n",
    "\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37681263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
