{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86e0394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv',usecols = ['category','data'])\n",
    "test = pd.read_csv('test.csv',usecols = ['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13c0a194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'신혼부부위한 주택정책 보다 보육시설 늘려주세요.. 국민세금으로 일부를 위한 정책펴지 마시고\\\\n보편적으로 모든국민이 수긍할  수 있는 복지정책 펴 주시길 바랍니다.\\\\n저도 신혼부부이지만 당첨되는 사람 로또되는 이런주택정책 반대합니다.\\\\n국민세금을 일부 사람들에게 퍼주기식이 되면 안되죠..\\\\n그 세금으로 우리아이 안전하게 맡길 수 있는 보육시설을 전국에 설치해 주세요..\\\\n대기업들은 솔선수범해서 모든 사업장에 의무설치 할 수 있도록 하시구요..\\\\n집 보다 애 맡길데가 없어 경력단절 되는게 더 괴롭습니다.!\\\\n집은 개인의 능력을 키워 사는게 맞습니다.\\\\n그 능력을 키울수 있도록 육아 전담에 힘을 기울이는게 맞습니다.\\\\n우리아이 부모가 키우는거 맞지만 이제는 국가가\\\\n책임지는 시대로 가는게 맞다고 봅니다.\\\\n그렇잖아도 부동산 가격 자꾸 올라가는게 정부정책이 잘못 되었다고 봅니다.\\\\n부동산은 그냥 내버려 두세요!  좀!\\\\n건들수록 역효과네요..'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66afc4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['data'] = train['data'].apply(lambda x : str(x).replace('\\\\n',' ')) # 텍스트 데이터에서 '\\\\n' 문자열을 ' '로 변경\n",
    "test['data'] = test['data'].apply(lambda x : str(x).replace('\\\\n',' ')) # 텍스트 데이터에서 '\\\\n' 문자열을 ' '로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dd0dd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'신혼부부위한 주택정책 보다 보육시설 늘려주세요.. 국민세금으로 일부를 위한 정책펴지 마시고 보편적으로 모든국민이 수긍할  수 있는 복지정책 펴 주시길 바랍니다. 저도 신혼부부이지만 당첨되는 사람 로또되는 이런주택정책 반대합니다. 국민세금을 일부 사람들에게 퍼주기식이 되면 안되죠.. 그 세금으로 우리아이 안전하게 맡길 수 있는 보육시설을 전국에 설치해 주세요.. 대기업들은 솔선수범해서 모든 사업장에 의무설치 할 수 있도록 하시구요.. 집 보다 애 맡길데가 없어 경력단절 되는게 더 괴롭습니다.! 집은 개인의 능력을 키워 사는게 맞습니다. 그 능력을 키울수 있도록 육아 전담에 힘을 기울이는게 맞습니다. 우리아이 부모가 키우는거 맞지만 이제는 국가가 책임지는 시대로 가는게 맞다고 봅니다. 그렇잖아도 부동산 가격 자꾸 올라가는게 정부정책이 잘못 되었다고 봅니다. 부동산은 그냥 내버려 두세요!  좀! 건들수록 역효과네요..'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de756d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cef446da",
   "metadata": {},
   "source": [
    "# 형태소 분석기"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0fd51950",
   "metadata": {},
   "source": [
    "Okt, Komoran, Kkma 총 3개\n",
    "Okt, Komoran, Kkma 은 모두 konlpy 라이브러리에서 불러올 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d53af4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma, Komoran, Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79823e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기 정의\n",
    "okt = Okt()\n",
    "kkm = Kkma()\n",
    "kom = Komoran()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8de7d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "#형태소를 분석할 텍스트 정의\n",
    "text = '마음에 꽂힌 칼한자루 보다 마음에 꽂힌 꽃한송이가 더 아파서 잠이 오지 않는다'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "763b476b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('마음', 'NNG'),\n",
       " ('에', 'JKB'),\n",
       " ('꽂히', 'VV'),\n",
       " ('ㄴ', 'ETM'),\n",
       " ('칼', 'NNG'),\n",
       " ('한자', 'NNP'),\n",
       " ('루', 'JKB'),\n",
       " ('보다', 'MAG'),\n",
       " ('마음', 'NNG'),\n",
       " ('에', 'JKB'),\n",
       " ('꽂히', 'VV'),\n",
       " ('ㄴ', 'ETM'),\n",
       " ('꽃', 'NNG'),\n",
       " ('한송이', 'NNP'),\n",
       " ('가', 'JKS'),\n",
       " ('더', 'MAG'),\n",
       " ('아파서', 'NNP'),\n",
       " ('잠', 'NNG'),\n",
       " ('이', 'JKS'),\n",
       " ('오', 'VV'),\n",
       " ('지', 'EC'),\n",
       " ('않', 'VX'),\n",
       " ('는다', 'EC')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 형태소 분석기의 pos메소드를 이용해 형태소를 분석 \n",
    "kom.pos(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5534b7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('마음', 'NNG'),\n",
       " ('에', 'JKM'),\n",
       " ('꽂히', 'VV'),\n",
       " ('ㄴ', 'ETD'),\n",
       " ('칼', 'NNG'),\n",
       " ('한자', 'NNG'),\n",
       " ('로', 'JKM'),\n",
       " ('보다', 'MAG'),\n",
       " ('마음', 'NNG'),\n",
       " ('에', 'JKM'),\n",
       " ('꽂히', 'VV'),\n",
       " ('ㄴ', 'ETD'),\n",
       " ('꽃', 'NNG'),\n",
       " ('한', 'MDN'),\n",
       " ('송이', 'NNG'),\n",
       " ('가', 'JKS'),\n",
       " ('더', 'MAG'),\n",
       " ('아프', 'VA'),\n",
       " ('아서', 'ECD'),\n",
       " ('잠', 'NNG'),\n",
       " ('이', 'JKS'),\n",
       " ('오', 'VV'),\n",
       " ('지', 'ECD'),\n",
       " ('않', 'VXV'),\n",
       " ('는', 'EPT'),\n",
       " ('다', 'EFN')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 형태소 분석기의 pos메소드를 이용해 형태소를 분석 \n",
    "kkm.pos(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1d67f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('마음', 'Noun'),\n",
       " ('에', 'Josa'),\n",
       " ('꽂히다', 'Verb'),\n",
       " ('칼', 'Noun'),\n",
       " ('한', 'Determiner'),\n",
       " ('자루', 'Noun'),\n",
       " ('보다', 'Verb'),\n",
       " ('마음', 'Noun'),\n",
       " ('에', 'Josa'),\n",
       " ('꽂히다', 'Verb'),\n",
       " ('꽃', 'Noun'),\n",
       " ('한송이', 'Noun'),\n",
       " ('가', 'Josa'),\n",
       " ('더', 'Noun'),\n",
       " ('아프다', 'Adjective'),\n",
       " ('잠', 'Noun'),\n",
       " ('이', 'Josa'),\n",
       " ('오지', 'Noun'),\n",
       " ('않다', 'Verb')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 형태소 분석기의 pos메소드를 이용해 형태소를 분석 \n",
    "# 단어들을 알아서 정규화 해주고, 오타도 수정해주는 기능, 어간 추출\n",
    "okt.pos(text,norm=True, stem=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29289214",
   "metadata": {},
   "source": [
    "=> Kkma와 Komoran이 okt 보다 더 구체적으로 형태소에 따라 단어를 쪼개줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3491de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4541b6e1",
   "metadata": {},
   "source": [
    "# 조사 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84bd028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조사를 제거하기 위함 함수 정의 \n",
    "def func(text):\n",
    "  # 형태소 분석\n",
    "  okt_pos = okt.pos(str(text),norm=True, stem=True)\n",
    "  \n",
    "  # 조사를 제거한 새로운 문자열 정의 \n",
    "  new_word = ''\n",
    "\n",
    "  for word,pos in okt_pos:\n",
    "    \n",
    "    # 품사가 조사가 아니면\n",
    "    if pos != 'Josa':\n",
    "      new_word+=word\n",
    "  \n",
    "  return new_word\n",
    "\n",
    "train['data'] = train['data'].apply(lambda x : func(x))\n",
    "test['data'] = test['data'].apply(lambda x : func(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4b16bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9b4340a",
   "metadata": {},
   "source": [
    "# TF-IDF를 이용하여 청와대 청원 데이터를 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85eaddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv',usecols = ['category','data'])\n",
    "test = pd.read_csv('test.csv',usecols = ['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67550b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['data'] = train['data'].apply(lambda x : str(x).replace('\\\\n',' ')) # 텍스트 데이터에서 '\\\\n' 문자열을 ' '로 변경\n",
    "test['data'] = test['data'].apply(lambda x : str(x).replace('\\\\n',' ')) # 텍스트 데이터에서 '\\\\n' 문자열을 ' '로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fd79e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(' ',inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf96f0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 데이터 사이즈 (40000, 697226)\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF으로 train 데이터를 피처 벡터화 변환 수행\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect = TfidfVectorizer()\n",
    "vect.fit(train['data'])\n",
    "train_x =  vect.transform(train['data'])\n",
    "\n",
    "print('train 데이터 사이즈', train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fbd9075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 데이터 사이즈 (5000, 697226)\n"
     ]
    }
   ],
   "source": [
    "#Train Data로 fit()된 TF-IDF를 이용해 테스트 데이터를 Feature Vector화 변환 수행\n",
    "\n",
    "test_x =  vect.transform(test['data'])\n",
    "print('test 데이터 사이즈', test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7272ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3927bfb9",
   "metadata": {},
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0bf0ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split() 메소드를 이용해 train/validation 데이터 나누기 \n",
    "# stratify 옵션을 활용하여 데이터 셋 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_valid, y_train, y_valid = train_test_split(train_x,train['category'],stratify = train['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "749919ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 0.625583\tvalid_1's l2: 0.626951\n",
      "[2]\ttraining's l2: 0.591771\tvalid_1's l2: 0.594434\n",
      "[3]\ttraining's l2: 0.563711\tvalid_1's l2: 0.568247\n",
      "[4]\ttraining's l2: 0.539804\tvalid_1's l2: 0.545114\n",
      "[5]\ttraining's l2: 0.519618\tvalid_1's l2: 0.526269\n",
      "[6]\ttraining's l2: 0.502115\tvalid_1's l2: 0.509254\n",
      "[7]\ttraining's l2: 0.487309\tvalid_1's l2: 0.495327\n",
      "[8]\ttraining's l2: 0.474058\tvalid_1's l2: 0.483028\n",
      "[9]\ttraining's l2: 0.462085\tvalid_1's l2: 0.472768\n",
      "[10]\ttraining's l2: 0.451848\tvalid_1's l2: 0.463296\n",
      "[11]\ttraining's l2: 0.442122\tvalid_1's l2: 0.454711\n",
      "[12]\ttraining's l2: 0.433435\tvalid_1's l2: 0.446885\n",
      "[13]\ttraining's l2: 0.425565\tvalid_1's l2: 0.440004\n",
      "[14]\ttraining's l2: 0.418527\tvalid_1's l2: 0.433493\n",
      "[15]\ttraining's l2: 0.412145\tvalid_1's l2: 0.427916\n",
      "[16]\ttraining's l2: 0.406273\tvalid_1's l2: 0.422626\n",
      "[17]\ttraining's l2: 0.400764\tvalid_1's l2: 0.418047\n",
      "[18]\ttraining's l2: 0.395736\tvalid_1's l2: 0.413516\n",
      "[19]\ttraining's l2: 0.391188\tvalid_1's l2: 0.409178\n",
      "[20]\ttraining's l2: 0.387044\tvalid_1's l2: 0.405858\n",
      "[21]\ttraining's l2: 0.382897\tvalid_1's l2: 0.402295\n",
      "[22]\ttraining's l2: 0.379164\tvalid_1's l2: 0.39938\n",
      "[23]\ttraining's l2: 0.375667\tvalid_1's l2: 0.396455\n",
      "[24]\ttraining's l2: 0.372317\tvalid_1's l2: 0.39362\n",
      "[25]\ttraining's l2: 0.369243\tvalid_1's l2: 0.391217\n",
      "[26]\ttraining's l2: 0.366344\tvalid_1's l2: 0.388766\n",
      "[27]\ttraining's l2: 0.36363\tvalid_1's l2: 0.386582\n",
      "[28]\ttraining's l2: 0.360998\tvalid_1's l2: 0.384646\n",
      "[29]\ttraining's l2: 0.358537\tvalid_1's l2: 0.3828\n",
      "[30]\ttraining's l2: 0.356186\tvalid_1's l2: 0.381012\n",
      "[31]\ttraining's l2: 0.353864\tvalid_1's l2: 0.379186\n",
      "[32]\ttraining's l2: 0.351689\tvalid_1's l2: 0.377252\n",
      "[33]\ttraining's l2: 0.349691\tvalid_1's l2: 0.376046\n",
      "[34]\ttraining's l2: 0.347807\tvalid_1's l2: 0.374708\n",
      "[35]\ttraining's l2: 0.345887\tvalid_1's l2: 0.373424\n",
      "[36]\ttraining's l2: 0.344091\tvalid_1's l2: 0.372101\n",
      "[37]\ttraining's l2: 0.342318\tvalid_1's l2: 0.370954\n",
      "[38]\ttraining's l2: 0.340639\tvalid_1's l2: 0.369625\n",
      "[39]\ttraining's l2: 0.339005\tvalid_1's l2: 0.368359\n",
      "[40]\ttraining's l2: 0.337461\tvalid_1's l2: 0.367535\n",
      "[41]\ttraining's l2: 0.335963\tvalid_1's l2: 0.366523\n",
      "[42]\ttraining's l2: 0.334512\tvalid_1's l2: 0.365806\n",
      "[43]\ttraining's l2: 0.33302\tvalid_1's l2: 0.364774\n",
      "[44]\ttraining's l2: 0.331609\tvalid_1's l2: 0.364139\n",
      "[45]\ttraining's l2: 0.33026\tvalid_1's l2: 0.363413\n",
      "[46]\ttraining's l2: 0.328972\tvalid_1's l2: 0.362545\n",
      "[47]\ttraining's l2: 0.327724\tvalid_1's l2: 0.361809\n",
      "[48]\ttraining's l2: 0.326522\tvalid_1's l2: 0.361079\n",
      "[49]\ttraining's l2: 0.325293\tvalid_1's l2: 0.360268\n",
      "[50]\ttraining's l2: 0.324112\tvalid_1's l2: 0.359662\n",
      "[51]\ttraining's l2: 0.322973\tvalid_1's l2: 0.358871\n",
      "[52]\ttraining's l2: 0.321805\tvalid_1's l2: 0.358261\n",
      "[53]\ttraining's l2: 0.320707\tvalid_1's l2: 0.357633\n",
      "[54]\ttraining's l2: 0.319654\tvalid_1's l2: 0.357133\n",
      "[55]\ttraining's l2: 0.318658\tvalid_1's l2: 0.356518\n",
      "[56]\ttraining's l2: 0.317577\tvalid_1's l2: 0.355916\n",
      "[57]\ttraining's l2: 0.316566\tvalid_1's l2: 0.355565\n",
      "[58]\ttraining's l2: 0.315578\tvalid_1's l2: 0.355069\n",
      "[59]\ttraining's l2: 0.314621\tvalid_1's l2: 0.354963\n",
      "[60]\ttraining's l2: 0.313646\tvalid_1's l2: 0.354332\n",
      "[61]\ttraining's l2: 0.312718\tvalid_1's l2: 0.35388\n",
      "[62]\ttraining's l2: 0.311817\tvalid_1's l2: 0.353364\n",
      "[63]\ttraining's l2: 0.310878\tvalid_1's l2: 0.353024\n",
      "[64]\ttraining's l2: 0.309916\tvalid_1's l2: 0.35275\n",
      "[65]\ttraining's l2: 0.308974\tvalid_1's l2: 0.352491\n",
      "[66]\ttraining's l2: 0.308087\tvalid_1's l2: 0.352188\n",
      "[67]\ttraining's l2: 0.307236\tvalid_1's l2: 0.351604\n",
      "[68]\ttraining's l2: 0.306388\tvalid_1's l2: 0.351263\n",
      "[69]\ttraining's l2: 0.305564\tvalid_1's l2: 0.350899\n",
      "[70]\ttraining's l2: 0.304677\tvalid_1's l2: 0.350691\n",
      "[71]\ttraining's l2: 0.303841\tvalid_1's l2: 0.350309\n",
      "[72]\ttraining's l2: 0.303056\tvalid_1's l2: 0.349934\n",
      "[73]\ttraining's l2: 0.302281\tvalid_1's l2: 0.349637\n",
      "[74]\ttraining's l2: 0.301515\tvalid_1's l2: 0.349238\n",
      "[75]\ttraining's l2: 0.300765\tvalid_1's l2: 0.348828\n",
      "[76]\ttraining's l2: 0.300035\tvalid_1's l2: 0.348501\n",
      "[77]\ttraining's l2: 0.299321\tvalid_1's l2: 0.348175\n",
      "[78]\ttraining's l2: 0.298508\tvalid_1's l2: 0.348041\n",
      "[79]\ttraining's l2: 0.297688\tvalid_1's l2: 0.347808\n",
      "[80]\ttraining's l2: 0.296962\tvalid_1's l2: 0.347467\n",
      "[81]\ttraining's l2: 0.296223\tvalid_1's l2: 0.347162\n",
      "[82]\ttraining's l2: 0.295532\tvalid_1's l2: 0.346775\n",
      "[83]\ttraining's l2: 0.294831\tvalid_1's l2: 0.346588\n",
      "[84]\ttraining's l2: 0.294124\tvalid_1's l2: 0.346344\n",
      "[85]\ttraining's l2: 0.293454\tvalid_1's l2: 0.346226\n",
      "[86]\ttraining's l2: 0.29278\tvalid_1's l2: 0.345932\n",
      "[87]\ttraining's l2: 0.292126\tvalid_1's l2: 0.345711\n",
      "[88]\ttraining's l2: 0.291475\tvalid_1's l2: 0.345443\n",
      "[89]\ttraining's l2: 0.290848\tvalid_1's l2: 0.345174\n",
      "[90]\ttraining's l2: 0.29021\tvalid_1's l2: 0.344962\n",
      "[91]\ttraining's l2: 0.289509\tvalid_1's l2: 0.344701\n",
      "[92]\ttraining's l2: 0.288877\tvalid_1's l2: 0.344479\n",
      "[93]\ttraining's l2: 0.288261\tvalid_1's l2: 0.344248\n",
      "[94]\ttraining's l2: 0.287615\tvalid_1's l2: 0.344155\n",
      "[95]\ttraining's l2: 0.286847\tvalid_1's l2: 0.343649\n",
      "[96]\ttraining's l2: 0.286211\tvalid_1's l2: 0.343441\n",
      "[97]\ttraining's l2: 0.285613\tvalid_1's l2: 0.343095\n",
      "[98]\ttraining's l2: 0.28495\tvalid_1's l2: 0.34303\n",
      "[99]\ttraining's l2: 0.284374\tvalid_1's l2: 0.342902\n",
      "[100]\ttraining's l2: 0.283781\tvalid_1's l2: 0.342871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LightGBM을 이용해 학습 및 검증 진행\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "model = LGBMRegressor(  )\n",
    "model.fit(x_train,y_train,\n",
    "          eval_set = [(x_train,y_train),(x_valid,y_valid)]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7cc58bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82106\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tvalid_0's auc: 0.749119\tvalid_0's l2: 0.520784\tvalid_1's auc: 0.745249\tvalid_1's l2: 0.523237\n",
      "[10]\tvalid_0's auc: 0.777979\tvalid_0's l2: 0.453579\tvalid_1's auc: 0.774483\tvalid_1's l2: 0.457639\n",
      "[15]\tvalid_0's auc: 0.794975\tvalid_0's l2: 0.414278\tvalid_1's auc: 0.792732\tvalid_1's l2: 0.418794\n",
      "[20]\tvalid_0's auc: 0.808649\tvalid_0's l2: 0.389349\tvalid_1's auc: 0.806462\tvalid_1's l2: 0.394193\n",
      "[25]\tvalid_0's auc: 0.819772\tvalid_0's l2: 0.372618\tvalid_1's auc: 0.818934\tvalid_1's l2: 0.37711\n",
      "[30]\tvalid_0's auc: 0.8305\tvalid_0's l2: 0.359879\tvalid_1's auc: 0.829585\tvalid_1's l2: 0.364329\n",
      "[35]\tvalid_0's auc: 0.840794\tvalid_0's l2: 0.350106\tvalid_1's auc: 0.84114\tvalid_1's l2: 0.354047\n",
      "[40]\tvalid_0's auc: 0.848224\tvalid_0's l2: 0.341921\tvalid_1's auc: 0.849251\tvalid_1's l2: 0.345874\n",
      "[45]\tvalid_0's auc: 0.852758\tvalid_0's l2: 0.335195\tvalid_1's auc: 0.853725\tvalid_1's l2: 0.33877\n",
      "[50]\tvalid_0's auc: 0.856772\tvalid_0's l2: 0.329233\tvalid_1's auc: 0.857965\tvalid_1's l2: 0.33283\n",
      "[55]\tvalid_0's auc: 0.86172\tvalid_0's l2: 0.32406\tvalid_1's auc: 0.863568\tvalid_1's l2: 0.327471\n",
      "[60]\tvalid_0's auc: 0.86523\tvalid_0's l2: 0.319301\tvalid_1's auc: 0.86823\tvalid_1's l2: 0.322297\n",
      "[65]\tvalid_0's auc: 0.868907\tvalid_0's l2: 0.315028\tvalid_1's auc: 0.872131\tvalid_1's l2: 0.317956\n",
      "[70]\tvalid_0's auc: 0.872664\tvalid_0's l2: 0.311086\tvalid_1's auc: 0.875553\tvalid_1's l2: 0.313922\n",
      "[75]\tvalid_0's auc: 0.875317\tvalid_0's l2: 0.307422\tvalid_1's auc: 0.877822\tvalid_1's l2: 0.310121\n",
      "[80]\tvalid_0's auc: 0.877806\tvalid_0's l2: 0.304096\tvalid_1's auc: 0.880776\tvalid_1's l2: 0.306317\n",
      "[85]\tvalid_0's auc: 0.880286\tvalid_0's l2: 0.300877\tvalid_1's auc: 0.883354\tvalid_1's l2: 0.303083\n",
      "[90]\tvalid_0's auc: 0.882931\tvalid_0's l2: 0.297838\tvalid_1's auc: 0.88587\tvalid_1's l2: 0.299829\n",
      "[95]\tvalid_0's auc: 0.885182\tvalid_0's l2: 0.294763\tvalid_1's auc: 0.887969\tvalid_1's l2: 0.29688\n",
      "[100]\tvalid_0's auc: 0.887348\tvalid_0's l2: 0.291934\tvalid_1's auc: 0.889989\tvalid_1's l2: 0.293798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LightGBM을 이용해 학습 및 검증 진행\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "model = LGBMRegressor()\n",
    "\n",
    "#평가 산식을 AUC로 설정, n_estimators 기준 5번 마다 결과값 출력하게 모델 학습.\n",
    "model.fit(train_x,train['category'], \n",
    "           eval_set = [(x_train,y_train),(x_valid,y_valid)],\n",
    "          eval_metric = 'auc' ,verbose = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22419bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
